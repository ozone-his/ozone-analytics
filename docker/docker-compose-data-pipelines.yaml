version: '3.8'
services:
  zookeeper:
    networks:
      ozone-analytics:
    restart: on-failure
    image: debezium/zookeeper:${DEBEZIUM_VERSION}
    ports:
     - 2181:2181
     - 2888:2888
     - 3888:3888
    volumes:
      - zookeeper-data:/zookeeper/data
      - zookeeper-txns:/zookeeper/txns
    labels: 
      kompose.service.type: clusterip
  kafka:
    networks:
      ozone-analytics:
    restart: on-failure
    image: debezium/kafka:${DEBEZIUM_VERSION}
    ports:
     - 9092:9092

    environment:
     - CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g
     - BROKER_ID=1
     - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
    volumes:
      - kafka-data:/kafka/data
    depends_on:
      - mysql
    healthcheck:
      test: ["/bin/bash", "-c", "./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --list"]
  kafka-setup:
    networks:
      ozone-analytics:
    restart: on-failure
    image: debezium/kafka:${DEBEZIUM_VERSION}
    command:
      - /bin/bash
      - -c
      - |
        IFS=',' read -ra topics <<< "$$TOPICS"
        for topic in $${topics[@]}
          do
            echo "Creating topic $$topic..."
            ./bin/kafka-topics.sh --create --topic openmrs.openmrs.$$topic --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka:9092
            ./bin/kafka-configs.sh --bootstrap-server=kafka:9092  --entity-type topics --entity-name openmrs.openmrs.$$topic --alter --add-config retention.ms=31556736000
        done
    environment:
     - TOPICS=${TOPICS}
    depends_on:
      - kafka
  connect:
    networks:
      ozone-analytics:
    restart: on-failure
    image: debezium/connect:${DEBEZIUM_VERSION}
    ports:
     - 8083:8083
    depends_on:
      - kafka-setup
      - mysql
    environment:
     - BOOTSTRAP_SERVERS=kafka:9092
     - GROUP_ID=1
     - CONFIG_STORAGE_TOPIC=my_connect_configs
     - OFFSET_STORAGE_TOPIC=my_connect_offsets
     - STATUS_STORAGE_TOPIC=my_connect_statuses
     - CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false
     - CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false
     - CONNECT_CONFIG_PROVIDERS=file
     - CONNECT_CONFIG_PROVIDERS_FILE_CLASS=org.apache.kafka.common.config.provider.FileConfigProvider
     - CONNECT_MYSQL_HOSTNAME=${CONNECT_MYSQL_HOSTNAME:-mysql}
     - CONNECT_MYSQL_USERNAME=${CONNECT_MYSQL_USERNAME:-root}
     - CONNECT_MYSQL_PASSWORD=${CONNECT_MYSQL_PASSWORD:-${MYSQL_ROOT_PASSWORD}}
     - CONNECT_MYSQL_PORT=${CONNECT_MYSQL_PORT:-${CONNECT_MYSQL_PORT}}
     - CONNECT_MYSQL_SERVER_ID=2
     - CONNECT_MYSQL_SERVER_NAME=openmrs
     - CONNECT_MYSQL_INCLUDE_LIST=openmrs
     - CONNECT_TABLE_EXCLUDE_LIST=openmrs.audit_log
     - CONNECT_MYSQL_HISTROY_TOPIC=dbhistory.openmrs
     - CONNECT_MYSQL_KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./debezium-connect/jars/TimestampConverter-1.2.4-SNAPSHOT.jar:/kafka/connect/debezium-connector-mysql/TimestampConverter-1.2.4-SNAPSHOT.jar
  connect-setup:
    networks:
      ozone-analytics:
    restart: on-failure
    build: ./setup-connect
    depends_on:
      - postgresql
      - mysql
      - jobmanager
      - taskmanager
      - connect
    environment:
      - CONNECT_HOST=connect
      - ANALYTICS_DB_HOST=${ANALYTICS_DB_HOST}
      - SOURCE_DB_HOST=${CONNECT_MYSQL_HOSTNAME}
      - FLINK_JOBMANAGER_HOST=jobmanager
  kowl:
    networks:
      ozone-analytics:
    image: quay.io/cloudhut/kowl:master
    container_name: "kowl"
    restart: on-failure
    entrypoint: /bin/sh
    command: -c "echo \"$$KOWL_CONFIG_FILE\" > /tmp/config.yml; /app/kowl"
    ports:
      - "8282:8080"
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      KOWL_CONFIG_FILE: |
        kafka:
          brokers: ["kafka:9092"]
        connect:
          enabled: true
          clusters:
            - name: openmrs
              url: http://connect:8083
    depends_on:
      - "kafka"
      - "connect"
    labels: 
      kompose.service.type: clusterip

  migrate:
    networks:
      ozone-analytics:
    restart: on-failure
    image: mekomsolutions/ozone-flink-jobs

    command: /run.sh
    depends_on:
      - postgresql
    environment:
      - FLINK_JOB_POSTGRES_USER=${ANALYTICS_DB_USER}
      - FLINK_JOB_POSTGRES_PASSWORD=${ANALYTICS_DB_PASSWORD}
      - FLINK_JOB_POSTGRES_URL=jdbc:postgresql://${ANALYTICS_DB_HOST}:${ANALYTICS_DB_PORT}/${ANALYTICS_DB_NAME}
      - FLINK_JOB_PROPERTIES_BOOTSTRAP_SERVERS=kafka:9092
    labels: 
      - kompose.service.group=flink-manager
  jobmanager:
    networks:
      ozone-analytics:
    restart: on-failure
    image: mekomsolutions/ozone-flink-jobs
    ports:
      - "8084:8081"
    command: standalone-job --job-classname net.mekomsolutions.data.pipelines.streaming.StreamingETLJob --job-id 00000000000000000000000000000000 --properties-file /opt/flink/usrlib/job.properties --sink-url jdbc:postgresql://${ANALYTICS_DB_HOST}:${ANALYTICS_DB_PORT}/${ANALYTICS_DB_NAME} --sink-username ${ANALYTICS_DB_USER} --sink-password ${ANALYTICS_DB_PASSWORD}
    depends_on:
       migrate:
         condition: service_completed_successfully
       zookeeper:
         condition: service_started
       kafka:
         condition: service_started
       kafka-setup:
         condition: service_completed_successfully
       postgresql:
         condition: service_started
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        io.tmp.dirs: /tmp/temp
        state.backend: rocksdb
        state.checkpoints.dir: file:///tmp/checkpoints/
        state.savepoints.dir: file:///tmp/savepoints
        execution.checkpointing.mode: EXACTLY_ONCE
        execution.checkpointing.unaligned: true  
        execution.checkpointing.interval: 30min
        execution.checkpointing.tolerable-failed-checkpoints: 100
        jobmanager.memory.process.size: ${JOB_MANAGER_PROCESS_MEMORY}
        state.checkpoints.num-retained: 4
        high-availability.storageDir: file:///tmp/ha
        high-availability: ZOOKEEPER
        high-availability.zookeeper.quorum: zookeeper:2181
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - FLINK_JOB_POSTGRES_USER=postgres
      - FLINK_JOB_POSTGRES_PASSWORD=password
      - FLINK_JOB_POSTGRES_URL=jdbc:postgresql://${ANALYTICS_DB_HOST}:${ANALYTICS_DB_PORT}/${ANALYTICS_DB_NAME}
      - FLINK_JOB_PROPERTIES_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - flink-shared-data:/tmp
      - ./flink/pipelines/job.properties:/opt/flink/usrlib/job.properties
      - ./data:/data
  taskmanager:
    networks:
      ozone-analytics:
    image: mekomsolutions/ozone-flink-jobs
    depends_on:
      - jobmanager
      - zookeeper
    command: taskmanager --properties-file /opt/flink/usrlib/job.properties
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 6
        io.tmp.dirs: /tmp/temp
        state.backend: rocksdb
        state.checkpoints.dir: file:///tmp/checkpoints/
        state.savepoints.dir: file:///tmp/savepoints
        execution.checkpointing.unaligned: true  
        execution.checkpointing.interval: 30min
        execution.checkpointing.tolerable-failed-checkpoints: 100
        taskmanager.memory.process.size: ${TASK_MANAGER_PROCESS_MEMORY}
        taskmanager.memory.managed.fraction: ${TASK_MANAGER_PROCESS_MANAGED_MEMORY_FRACTION}
        high-availability.storageDir: file:///tmp/ha
        high-availability: ZOOKEEPER
        high-availability.zookeeper.quorum: zookeeper:2181
        state.checkpoints.num-retained: 4
    volumes:
      - flink-shared-data:/tmp
      - ./flink/pipelines/job.properties:/opt/flink/usrlib/job.properties
      - ./data:/data
    restart: on-failure
volumes:
   mysql-data:
   flink-shared-data: ~
   postgresql-data: ~
   redis: ~
   zookeeper-data: ~
   kafka-data: ~
   zookeeper-txns: ~
   consul-data: ~
   openmrs-referenceapplication-data: ~
networks:
  ozone-analytics: